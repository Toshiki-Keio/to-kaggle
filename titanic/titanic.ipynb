{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toshikifukui/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#テストデータの整形\n",
    "Xtest = test_data[['Pclass',\"Age\",\"Sex\",\"Fare\",\"Embarked\"]]\n",
    "Xtest.loc[:,\"Sex\"] = Xtest[\"Sex\"].map({\"male\":0,\"female\":1})\n",
    "Xtest.loc[:,\"Embarked\"] = Xtest[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n",
    "Xtest.loc[:,\"Age\"] = Xtest[\"Age\"].fillna(Xtest[\"Age\"].mean())\n",
    "Xtest.loc[:,\"Fare\"] = Xtest[\"Fare\"].fillna(Xtest[\"Fare\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass        Age  Sex     Fare  Embarked\n",
       "0         3  22.000000    0   7.2500       0.0\n",
       "1         1  38.000000    1  71.2833       1.0\n",
       "2         3  26.000000    1   7.9250       0.0\n",
       "3         1  35.000000    1  53.1000       0.0\n",
       "4         3  35.000000    0   8.0500       0.0\n",
       "..      ...        ...  ...      ...       ...\n",
       "886       2  27.000000    0  13.0000       0.0\n",
       "887       1  19.000000    1  30.0000       0.0\n",
       "888       3  29.699118    1  23.4500       0.0\n",
       "889       1  26.000000    0  30.0000       1.0\n",
       "890       3  32.000000    0   7.7500       2.0\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習用データの整形\n",
    "train1 = train.drop(\"Survived\",axis=1)\n",
    "labels = train[\"Survived\"]\n",
    "trains = train1[[\"Pclass\",\"Age\",\"Sex\",\"Fare\",\"Embarked\"]]\n",
    "trains.loc[:,\"Embarked\"]  = trains[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n",
    "trains.loc[:,\"Embarked\"] = trains[\"Embarked\"].fillna(trains.Embarked.mean())\n",
    "trains.loc[:,\"Sex\"] = trains[\"Sex\"].map({\"male\":0,\"female\":1})\n",
    "trains.loc[:,\"Age\"] = trains[\"Age\"].fillna(trains[\"Age\"].mean())\n",
    "trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 300\n",
      "building tree 2 of 300\n",
      "building tree 3 of 300\n",
      "building tree 4 of 300\n",
      "building tree 5 of 300\n",
      "building tree 6 of 300\n",
      "building tree 7 of 300\n",
      "building tree 8 of 300\n",
      "building tree 9 of 300\n",
      "building tree 10 of 300\n",
      "building tree 11 of 300\n",
      "building tree 12 of 300\n",
      "building tree 13 of 300\n",
      "building tree 14 of 300\n",
      "building tree 15 of 300\n",
      "building tree 16 of 300\n",
      "building tree 17 of 300\n",
      "building tree 18 of 300\n",
      "building tree 19 of 300\n",
      "building tree 20 of 300\n",
      "building tree 21 of 300\n",
      "building tree 22 of 300\n",
      "building tree 23 of 300\n",
      "building tree 24 of 300\n",
      "building tree 25 of 300\n",
      "building tree 26 of 300\n",
      "building tree 27 of 300\n",
      "building tree 28 of 300\n",
      "building tree 29 of 300\n",
      "building tree 30 of 300\n",
      "building tree 31 of 300\n",
      "building tree 32 of 300\n",
      "building tree 33 of 300\n",
      "building tree 34 of 300\n",
      "building tree 35 of 300\n",
      "building tree 36 of 300\n",
      "building tree 37 of 300\n",
      "building tree 38 of 300\n",
      "building tree 39 of 300\n",
      "building tree 40 of 300\n",
      "building tree 41 of 300\n",
      "building tree 42 of 300\n",
      "building tree 43 of 300\n",
      "building tree 44 of 300\n",
      "building tree 45 of 300\n",
      "building tree 46 of 300\n",
      "building tree 47 of 300\n",
      "building tree 48 of 300\n",
      "building tree 49 of 300\n",
      "building tree 50 of 300\n",
      "building tree 51 of 300\n",
      "building tree 52 of 300\n",
      "building tree 53 of 300\n",
      "building tree 54 of 300\n",
      "building tree 55 of 300\n",
      "building tree 56 of 300\n",
      "building tree 57 of 300\n",
      "building tree 58 of 300\n",
      "building tree 59 of 300\n",
      "building tree 60 of 300\n",
      "building tree 61 of 300\n",
      "building tree 62 of 300\n",
      "building tree 63 of 300\n",
      "building tree 64 of 300\n",
      "building tree 65 of 300\n",
      "building tree 66 of 300\n",
      "building tree 67 of 300\n",
      "building tree 68 of 300\n",
      "building tree 69 of 300\n",
      "building tree 70 of 300\n",
      "building tree 71 of 300\n",
      "building tree 72 of 300\n",
      "building tree 73 of 300\n",
      "building tree 74 of 300\n",
      "building tree 75 of 300\n",
      "building tree 76 of 300\n",
      "building tree 77 of 300\n",
      "building tree 78 of 300\n",
      "building tree 79 of 300\n",
      "building tree 80 of 300\n",
      "building tree 81 of 300\n",
      "building tree 82 of 300\n",
      "building tree 83 of 300\n",
      "building tree 84 of 300\n",
      "building tree 85 of 300\n",
      "building tree 86 of 300\n",
      "building tree 87 of 300\n",
      "building tree 88 of 300\n",
      "building tree 89 of 300\n",
      "building tree 90 of 300\n",
      "building tree 91 of 300\n",
      "building tree 92 of 300\n",
      "building tree 93 of 300\n",
      "building tree 94 of 300\n",
      "building tree 95 of 300\n",
      "building tree 96 of 300\n",
      "building tree 97 of 300\n",
      "building tree 98 of 300\n",
      "building tree 99 of 300\n",
      "building tree 100 of 300\n",
      "building tree 101 of 300\n",
      "building tree 102 of 300\n",
      "building tree 103 of 300\n",
      "building tree 104 of 300\n",
      "building tree 105 of 300\n",
      "building tree 106 of 300\n",
      "building tree 107 of 300\n",
      "building tree 108 of 300\n",
      "building tree 109 of 300\n",
      "building tree 110 of 300\n",
      "building tree 111 of 300\n",
      "building tree 112 of 300\n",
      "building tree 113 of 300\n",
      "building tree 114 of 300\n",
      "building tree 115 of 300\n",
      "building tree 116 of 300\n",
      "building tree 117 of 300\n",
      "building tree 118 of 300\n",
      "building tree 119 of 300\n",
      "building tree 120 of 300\n",
      "building tree 121 of 300\n",
      "building tree 122 of 300\n",
      "building tree 123 of 300\n",
      "building tree 124 of 300\n",
      "building tree 125 of 300\n",
      "building tree 126 of 300\n",
      "building tree 127 of 300\n",
      "building tree 128 of 300\n",
      "building tree 129 of 300\n",
      "building tree 130 of 300\n",
      "building tree 131 of 300\n",
      "building tree 132 of 300\n",
      "building tree 133 of 300\n",
      "building tree 134 of 300\n",
      "building tree 135 of 300\n",
      "building tree 136 of 300\n",
      "building tree 137 of 300\n",
      "building tree 138 of 300\n",
      "building tree 139 of 300\n",
      "building tree 140 of 300\n",
      "building tree 141 of 300\n",
      "building tree 142 of 300\n",
      "building tree 143 of 300\n",
      "building tree 144 of 300\n",
      "building tree 145 of 300\n",
      "building tree 146 of 300\n",
      "building tree 147 of 300\n",
      "building tree 148 of 300\n",
      "building tree 149 of 300\n",
      "building tree 150 of 300\n",
      "building tree 151 of 300\n",
      "building tree 152 of 300\n",
      "building tree 153 of 300\n",
      "building tree 154 of 300\n",
      "building tree 155 of 300\n",
      "building tree 156 of 300\n",
      "building tree 157 of 300\n",
      "building tree 158 of 300\n",
      "building tree 159 of 300\n",
      "building tree 160 of 300\n",
      "building tree 161 of 300\n",
      "building tree 162 of 300\n",
      "building tree 163 of 300\n",
      "building tree 164 of 300\n",
      "building tree 165 of 300\n",
      "building tree 166 of 300\n",
      "building tree 167 of 300\n",
      "building tree 168 of 300\n",
      "building tree 169 of 300\n",
      "building tree 170 of 300\n",
      "building tree 171 of 300\n",
      "building tree 172 of 300\n",
      "building tree 173 of 300\n",
      "building tree 174 of 300\n",
      "building tree 175 of 300\n",
      "building tree 176 of 300\n",
      "building tree 177 of 300\n",
      "building tree 178 of 300\n",
      "building tree 179 of 300\n",
      "building tree 180 of 300\n",
      "building tree 181 of 300\n",
      "building tree 182 of 300\n",
      "building tree 183 of 300\n",
      "building tree 184 of 300\n",
      "building tree 185 of 300\n",
      "building tree 186 of 300\n",
      "building tree 187 of 300\n",
      "building tree 188 of 300\n",
      "building tree 189 of 300\n",
      "building tree 190 of 300\n",
      "building tree 191 of 300\n",
      "building tree 192 of 300\n",
      "building tree 193 of 300\n",
      "building tree 194 of 300\n",
      "building tree 195 of 300\n",
      "building tree 196 of 300\n",
      "building tree 197 of 300\n",
      "building tree 198 of 300\n",
      "building tree 199 of 300\n",
      "building tree 200 of 300\n",
      "building tree 201 of 300\n",
      "building tree 202 of 300\n",
      "building tree 203 of 300\n",
      "building tree 204 of 300\n",
      "building tree 205 of 300\n",
      "building tree 206 of 300\n",
      "building tree 207 of 300\n",
      "building tree 208 of 300\n",
      "building tree 209 of 300\n",
      "building tree 210 of 300\n",
      "building tree 211 of 300\n",
      "building tree 212 of 300\n",
      "building tree 213 of 300\n",
      "building tree 214 of 300\n",
      "building tree 215 of 300\n",
      "building tree 216 of 300\n",
      "building tree 217 of 300\n",
      "building tree 218 of 300\n",
      "building tree 219 of 300\n",
      "building tree 220 of 300\n",
      "building tree 221 of 300\n",
      "building tree 222 of 300\n",
      "building tree 223 of 300\n",
      "building tree 224 of 300\n",
      "building tree 225 of 300\n",
      "building tree 226 of 300\n",
      "building tree 227 of 300\n",
      "building tree 228 of 300\n",
      "building tree 229 of 300\n",
      "building tree 230 of 300\n",
      "building tree 231 of 300\n",
      "building tree 232 of 300\n",
      "building tree 233 of 300\n",
      "building tree 234 of 300\n",
      "building tree 235 of 300\n",
      "building tree 236 of 300\n",
      "building tree 237 of 300\n",
      "building tree 238 of 300\n",
      "building tree 239 of 300\n",
      "building tree 240 of 300\n",
      "building tree 241 of 300\n",
      "building tree 242 of 300\n",
      "building tree 243 of 300\n",
      "building tree 244 of 300\n",
      "building tree 245 of 300\n",
      "building tree 246 of 300\n",
      "building tree 247 of 300\n",
      "building tree 248 of 300\n",
      "building tree 249 of 300\n",
      "building tree 250 of 300\n",
      "building tree 251 of 300\n",
      "building tree 252 of 300\n",
      "building tree 253 of 300\n",
      "building tree 254 of 300\n",
      "building tree 255 of 300\n",
      "building tree 256 of 300\n",
      "building tree 257 of 300\n",
      "building tree 258 of 300\n",
      "building tree 259 of 300\n",
      "building tree 260 of 300\n",
      "building tree 261 of 300\n",
      "building tree 262 of 300\n",
      "building tree 263 of 300\n",
      "building tree 264 of 300\n",
      "building tree 265 of 300\n",
      "building tree 266 of 300\n",
      "building tree 267 of 300\n",
      "building tree 268 of 300\n",
      "building tree 269 of 300\n",
      "building tree 270 of 300\n",
      "building tree 271 of 300\n",
      "building tree 272 of 300\n",
      "building tree 273 of 300\n",
      "building tree 274 of 300\n",
      "building tree 275 of 300\n",
      "building tree 276 of 300\n",
      "building tree 277 of 300\n",
      "building tree 278 of 300\n",
      "building tree 279 of 300\n",
      "building tree 280 of 300\n",
      "building tree 281 of 300\n",
      "building tree 282 of 300\n",
      "building tree 283 of 300\n",
      "building tree 284 of 300\n",
      "building tree 285 of 300\n",
      "building tree 286 of 300\n",
      "building tree 287 of 300\n",
      "building tree 288 of 300\n",
      "building tree 289 of 300\n",
      "building tree 290 of 300\n",
      "building tree 291 of 300\n",
      "building tree 292 of 300\n",
      "building tree 293 of 300\n",
      "building tree 294 of 300\n",
      "building tree 295 of 300\n",
      "building tree 296 of 300\n",
      "building tree 297 of 300\n",
      "building tree 298 of 300\n",
      "building tree 299 of 300\n",
      "building tree 300 of 300\n",
      "ランダムフォレストの精度:0.8430493273542601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#randomforest_score\n",
    "x_train,x_test,y_train,y_test = train_test_split(trains,labels,test_size = 0.25)\n",
    "forest = RandomForestClassifier(n_estimators=300,random_state=23,verbose=2,max_depth=4)\n",
    "#n_estimators...決定木の数, max_depth...深さ, criterion...エントロピーを指標とするインスタンス生成\n",
    "forest.fit(x_train,y_train)\n",
    "y_pred_forest = forest.predict(Xtest)\n",
    "forest_score = forest.score(x_test,y_test)\n",
    "print(\"ランダムフォレストの精度:{}\".format(forest_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの整形-Randomforest\n",
    "submitPre = pd.DataFrame({\n",
    "                        'PassengerId':test_data['PassengerId'],\n",
    "                        'Survived':y_pred_forest\n",
    "                        })\n",
    "# CSV出力\n",
    "submitPre.to_csv(\"random_forest.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰の精度：0.8071748878923767\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "model = LogisticRegression()\n",
    "x_train,x_test,y_train,y_test = train_test_split(trains,labels,test_size = 0.25)\n",
    "model.fit(x_train,y_train)\n",
    "print(\"ロジスティック回帰の精度：{}\".format(model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの整形-Logistic\n",
    "submitPre = pd.DataFrame({\n",
    "                        'PassengerId':test_data['PassengerId'],\n",
    "                        'Survived':y_pred_forest\n",
    "                        })\n",
    "# CSV出力\n",
    "submitPre.to_csv(\"gender_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-450-e3a7a8e11063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mbest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GridSearchCVの精度:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    155\u001b[0m                                            n_samples_bootstrap)\n\u001b[1;32m    156\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'subsample'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#gridsearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'n_estimators' :[3,5,10,30,50],#作成する決定木の数\n",
    "    'random_state' :[7,42],\n",
    "    'max_depth' :[3,5,8,10],#決定木の深さ\n",
    "    'min_samples_leaf': [2,5,10,20,50],#分岐し終わったノードの最小サンプル数\n",
    "    'min_samples_split': [2,5,10,20,50]#決定木が分岐する際に必要なサンプル数\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, cv=2, iid=False)\n",
    "clf.fit(x_train,y_train) \n",
    "best_clf = clf.best_estimator_\n",
    "print(\"GridSearchCVの精度:{}\".format(best_clf.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = best_clf.predict(Xtest)\n",
    "# データの整形\n",
    "submitPre = pd.DataFrame({\n",
    "                        'PassengerId':test_data['PassengerId'],\n",
    "                        'Survived':y_pred_cv\n",
    "                        })\n",
    "# CSV出力\n",
    "submitPre.to_csv(\"grid_rearch_cv.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 0.434027\tvalid_1's binary_logloss: 0.454343\n",
      "[200]\ttraining's binary_logloss: 0.360051\tvalid_1's binary_logloss: 0.416391\n",
      "[300]\ttraining's binary_logloss: 0.313411\tvalid_1's binary_logloss: 0.411785\n",
      "[400]\ttraining's binary_logloss: 0.275747\tvalid_1's binary_logloss: 0.41079\n",
      "[500]\ttraining's binary_logloss: 0.248971\tvalid_1's binary_logloss: 0.414852\n",
      "[600]\ttraining's binary_logloss: 0.228212\tvalid_1's binary_logloss: 0.419089\n",
      "[700]\ttraining's binary_logloss: 0.210874\tvalid_1's binary_logloss: 0.429458\n",
      "[800]\ttraining's binary_logloss: 0.196966\tvalid_1's binary_logloss: 0.438178\n",
      "[900]\ttraining's binary_logloss: 0.18495\tvalid_1's binary_logloss: 0.445573\n",
      "[1000]\ttraining's binary_logloss: 0.17431\tvalid_1's binary_logloss: 0.454352\n",
      "[1100]\ttraining's binary_logloss: 0.165303\tvalid_1's binary_logloss: 0.463621\n",
      "[1200]\ttraining's binary_logloss: 0.157415\tvalid_1's binary_logloss: 0.47094\n",
      "[1300]\ttraining's binary_logloss: 0.149775\tvalid_1's binary_logloss: 0.480408\n",
      "[1400]\ttraining's binary_logloss: 0.142954\tvalid_1's binary_logloss: 0.489089\n",
      "[1500]\ttraining's binary_logloss: 0.136646\tvalid_1's binary_logloss: 0.498605\n",
      "[1600]\ttraining's binary_logloss: 0.131072\tvalid_1's binary_logloss: 0.50677\n",
      "[1700]\ttraining's binary_logloss: 0.125364\tvalid_1's binary_logloss: 0.513396\n",
      "[1800]\ttraining's binary_logloss: 0.120331\tvalid_1's binary_logloss: 0.523754\n",
      "[1900]\ttraining's binary_logloss: 0.115147\tvalid_1's binary_logloss: 0.529873\n",
      "[2000]\ttraining's binary_logloss: 0.110832\tvalid_1's binary_logloss: 0.535106\n",
      "[2100]\ttraining's binary_logloss: 0.106969\tvalid_1's binary_logloss: 0.540634\n",
      "[2200]\ttraining's binary_logloss: 0.102348\tvalid_1's binary_logloss: 0.551756\n",
      "[2300]\ttraining's binary_logloss: 0.0987191\tvalid_1's binary_logloss: 0.560277\n",
      "[2400]\ttraining's binary_logloss: 0.0955426\tvalid_1's binary_logloss: 0.569089\n",
      "[2500]\ttraining's binary_logloss: 0.0921394\tvalid_1's binary_logloss: 0.576585\n",
      "[2600]\ttraining's binary_logloss: 0.0893649\tvalid_1's binary_logloss: 0.581183\n",
      "[2700]\ttraining's binary_logloss: 0.086374\tvalid_1's binary_logloss: 0.591365\n",
      "[2800]\ttraining's binary_logloss: 0.0838603\tvalid_1's binary_logloss: 0.605158\n",
      "[2900]\ttraining's binary_logloss: 0.0810412\tvalid_1's binary_logloss: 0.618526\n",
      "[3000]\ttraining's binary_logloss: 0.0784757\tvalid_1's binary_logloss: 0.630857\n",
      "Best Score 0.6308569392041311\n",
      "RandomForestの精度 : 0.843\n",
      "LightGBMの精度 : 0.789\n"
     ]
    }
   ],
   "source": [
    "#Lightgbm\n",
    "import lightgbm as lgb\n",
    "dtrain = lgb.Dataset(x_train,label=y_train)\n",
    "dtest = lgb.Dataset(x_test,label=y_test)\n",
    "params = {\n",
    "    \"objective\":\"binary\",\n",
    "    \"random_state\":42,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"verbosity\": -1,\n",
    "    \"metrics\":\"binary_logloss\"\n",
    "}\n",
    "bstc = lgb.train(params, dtrain, num_boost_round=3000,valid_sets=[dtrain, dtest],verbose_eval=100)\n",
    "print(\"Best Score\", bstc.best_score[\"valid_1\"]['binary_logloss'])\n",
    "#精度の向上\n",
    "y_pred = (bstc.predict(x_test)>0.5)\n",
    "accuracy_cancer = (y_test == y_pred).sum()/len(y_test)\n",
    "#Breast Cancerの比較\n",
    "print(\"RandomForestの精度 : {:.3f}\".format(forest_score))\n",
    "print(\"LightGBMの精度 : {:.3f}\".format(accuracy_cancer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_light = (bstc.predict(Xtest)>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False, False,  True,  True,  True, False,\n",
       "       False, False, False,  True, False,  True, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "        True, False,  True,  True, False, False,  True,  True, False,\n",
       "       False, False,  True, False,  True,  True, False,  True,  True,\n",
       "       False, False, False, False, False,  True,  True, False,  True,\n",
       "       False, False,  True,  True,  True, False,  True, False,  True,\n",
       "       False,  True, False, False, False,  True, False, False, False,\n",
       "        True, False, False, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True,  True,  True, False, False,  True,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "        True, False, False, False,  True,  True,  True,  True,  True,\n",
       "       False, False,  True, False,  True, False,  True,  True, False,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "       False, False,  True,  True, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "        True, False,  True,  True,  True, False,  True, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "        True, False,  True, False,  True,  True, False,  True, False,\n",
       "       False, False, False,  True, False,  True, False,  True,  True,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False,  True, False, False, False,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "        True, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False,  True, False, False, False,  True,  True,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False,  True,  True,  True,  True, False, False, False,  True,\n",
       "        True, False,  True, False, False,  True,  True, False, False,\n",
       "       False,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False,  True,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "        True, False,  True,  True])"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの整形-lightgbm\n",
    "y_pred_light \n",
    "submitPre = pd.DataFrame({\n",
    "                        'PassengerId':test_data['PassengerId'],\n",
    "                        'Survived':y_pred_light\n",
    "                        })\n",
    "# CSV出力\n",
    "submitPre.to_csv(\"lightgbm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVCの精度:0.6401869158878505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toshikifukui/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "train_data = train[[\"Survived\",\"Pclass\",\"Age\",\"Sex\",\"Fare\",\"Embarked\"]]\n",
    "train_data.loc[:,\"Embarked\"]  = train_data[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n",
    "train_data.loc[:,\"Sex\"] = train_data[\"Sex\"].map({\"male\":0,\"female\":1})\n",
    "train_data = train_data.dropna()\n",
    "labels = train_data[\"Survived\"]\n",
    "train_data = train_data.drop(\"Survived\",axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,labels , test_size=0.3)\n",
    "\n",
    "# データの標準化処理\n",
    "clr = make_pipeline(StandardScaler(),SVC(kernel=\"rbf\",gamma=0.5))\n",
    "clr.fit(X_train_std,y_train)\n",
    "print(\"SVCの精度:{}\".format(clr.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 300)               1800      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 182,701\n",
      "Trainable params: 182,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer=\"adam\",loss=\"mean_squared_error\",metrics=[\"accuracy\"])\n",
    "#mean_squared_errororbinary_crossentropy\n",
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.6189\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.6772\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.6225\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.6731\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.6785\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.6840\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.6786\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.6952\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7423\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.7292\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.7659\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.7736\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.7982\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.7678\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.7756\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.7629\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.7549\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7483\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.8126\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.8112\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.7989\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.7910\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.8016\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.7930\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.7859\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.8317\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.7654\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.8066\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.8076\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.7833\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.7955\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.8065\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.8311\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.7663\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.8166\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.7975\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.8311\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.8275\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.8123\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.7758\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.8106\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.8042\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.8144\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.8021\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.8329\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.8344\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.7985\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.8354\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.7910\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.8198\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.8243\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.8428\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.8217\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.8179\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.8091\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.8467\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.8012\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.8262\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.8205\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.8010\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.8234\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.8188\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.7990\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.8063\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.8248\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.8234\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.8005\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.7990\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.8128\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.8128\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.8369\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.8394\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.8156\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.8205\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.8152\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.8281\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.8264\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.8258\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.8468\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.8242\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.8055\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.8063\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.8453\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.8198\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.8102\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.8432\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.8020\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.7950\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.8253\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.8430\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.8234\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.8469\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.8323\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.8547\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.8356\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.8386\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.8300\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.8176\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.8139\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.8178\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.8189\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.8318\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.8257\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.8260\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.8240\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.8114\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.8088\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.8298\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.8321\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.8165\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.8578\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.8052\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.8228\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.8223\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.8444\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.8193\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.8491\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.8363\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.8380\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.8299\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.8596\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.8566\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.8450\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.8362\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.8348\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.8159\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.8391\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.8396\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.8320\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.8527\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.8214\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.8377\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.8436\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.8243\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.8052\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.8249\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.8544\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.8641\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.8399\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.8273\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.8584\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.8575\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.8444\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1099 - accuracy: 0.8567\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.8547\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.8457\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.8383\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.8284\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.8472\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.8560\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.8506\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.8648\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.8302\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.8526\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.8673\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.8576\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.8573\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.8487\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.8401\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.8582\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.8505\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.8439\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.8438\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.8514\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.8443\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.8455\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.8435\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.8506\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.8494\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.8527\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.8328\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.8496\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.8662\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.8261\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8339\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.8537\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.8144\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.8326\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.8653\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.8598\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.8568\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.8827\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.8796\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.8602\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.8736\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.8410\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.8465\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.8479\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.8450\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.8416\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.8580\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.8616\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.8731\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.8384\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.8512\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.8561\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.8434\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.8270\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.8656\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.8705\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.8668\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.8394\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.8844\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.8722\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.8744\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.8674\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.8650\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.8780\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.8765\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.8580\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.8563\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.8739\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.8826\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.8365\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.8396\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.8543\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.8673\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.8378\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.8586\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.8529\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.8680\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.8873\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.8870\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.8771\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.8717\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.8545\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.8602\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.8486\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.8487\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.8396\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.8700\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.8462\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.8588\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.8629\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.8743\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.8496\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.8530\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.8747\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.8511\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.8656\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.8670\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.8527\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.8716\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.8802\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.8796\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.8718\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.8613\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.8846\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.8621\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.8898\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.8682\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.8874\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.8723\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.8654\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.8932\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.8719\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.8830\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.8795\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.8923\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.8591\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.8493\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.8819\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.8541\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.8396\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.8670\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.8584\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.8499\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.8353\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.8476\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.8568\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.8532\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.8515\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9024\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.8853\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.8937\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.8686\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.8674\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.8728\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.8823\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.8691\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.8764\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.8839\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.8695\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.8703\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.8660\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.8929\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.8809\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.8564\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.8772\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.8684\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.8910\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 0.8711\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0854 - accuracy: 0.8860\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.8905\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.8857\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9005\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.8694\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.8718\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.8666\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fce47f48bd0>"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from keras.utils.np_utils import to_categorical\n",
    "# categorical_labels = to_categorical(y_train,num_classes=None)\n",
    "model_tf.fit(x_train,y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.8117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15219581127166748, 0.8116592168807983]"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = model_tf.predict(Xtest).T\n",
    "y_pred_nn = np.where(answer>0.5,1,0)\n",
    "y_pred_nn = y_pred_nn.reshape(418,)\n",
    "y_pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの整形\n",
    "submitPre = pd.DataFrame({\n",
    "                        'PassengerId':test_data['PassengerId'],\n",
    "                        'Survived':y_pred_nn\n",
    "                        })\n",
    "# CSV出力\n",
    "submitPre.to_csv(\"NeuralNet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 5)\n",
      "(623,)\n"
     ]
    }
   ],
   "source": [
    "#Pytorch型のデータを用意\n",
    "import torch\n",
    "train_values = trains.values\n",
    "test_values = labels.values\n",
    "x_train,x_test,y_train,y_test = train_test_split(train_values,test_values,test_size = 0.3)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_train =  torch.FloatTensor(x_train)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "train = TensorDataset(x_train,y_train)\n",
    "#ミニバッチを考慮したデータ\n",
    "train_loader = DataLoader(train, batch_size=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5,300)\n",
    "        self.fc2 = nn.Linear(300,300)\n",
    "        self.fc3 = nn.Linear(300,300)\n",
    "        self.fc4 = nn.Linear(300,2)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (fc1): Linear(in_features=5, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (fc3): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (fc4): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "#損失関数、最適化アルゴリズムを指定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor(9.4477)\n",
      "20 tensor(10.4718)\n",
      "30 tensor(7.2981)\n",
      "40 tensor(8.2211)\n",
      "50 tensor(6.3770)\n",
      "60 tensor(6.2484)\n",
      "70 tensor(6.4218)\n",
      "80 tensor(8.4361)\n"
     ]
    }
   ],
   "source": [
    "#500エポックの学習実行\n",
    "for epoch in range(80):\n",
    "    total_loss = 0\n",
    "    for train_x,train_y in train_loader:\n",
    "        optimizer.zero_grad()#初期勾配0\n",
    "        output = model(x_train)\n",
    "        loss = criterion(output,y_train)\n",
    "        loss.backward()#誤差逆伝播\n",
    "        optimizer.step()#パラメータ更新\n",
    "        total_loss += loss.data\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(epoch + 1,total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6977611940298507"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#テストデータの場合\n",
    "test_model = model(x_test).detach()\n",
    "#accracyの表示\n",
    "result = torch.max(test_model, 1)[1]\n",
    "accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb22ecf3850>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZDklEQVR4nO3de3Scd33n8fd3ZiRZkmXJ1ozvSuSLbMcJURxEbrZCKNsSrlkKlJguPeWEzUmXBFjYLbS7bc5Syinl0tBw22wacvakOAWSLTRA6AWoY+eGHCdObCeOZDu2HMeWfJN8022++8eMZPkiS7ZG+s0883mdo+OZ53nmmY/n2J959Jtnfo+5OyIiUvhioQOIiEhuqNBFRCJChS4iEhEqdBGRiFChi4hERCLUEyeTSa+vrw/19CIiBWnDhg2d7p4617pghV5fX09LS0uopxcRKUhm9tpI6zTkIiISESp0EZGIUKGLiESECl1EJCJU6CIiEaFCFxGJCBW6iEhEFFyhb9vXzRcf28LJvoHQUURE8krBFfqeQye4f90ONrx2KHQUEZG8UnCFfu3CGZTEjbWvdoSOIiKSVwqu0CtKE1x9yXTWvdoZOoqISF4puEIHaG5Isvn1Lg4c7QkdRUQkbxRooWcmGlvfdiBwEhGR/FGQhX7FvGqqy0t4YpvG0UVEBhVkocdjxsrFtaxr7cTdQ8cREckLBVnoAKsWp9h75CRtHcdCRxERyQsFW+jNDUkAntDpiyIiQAEXet2MCuprK3T6oohI1qiFbmYPmNl+M3vpPNvcZGbPm9lmM/v33EYc2aqGJE9vP0DfQHqynlJEJG+N5Qj9QeDmkVaaWQ3wbeB97n458KHcRBtdc0OKY70DbNx1eLKeUkQkb41a6O6+Fjh4nk0+Ajzq7ruy2+/PUbZRXb+olnjMNI4uIkJuxtCXANPN7NdmtsHM/mCkDc3sdjNrMbOWjo7xl/C0KSU0zq/mCY2ji4jkpNATwJuBdwPvAP7MzJaca0N3v8/dm9y9KZVK5eCpYVVDik3thzlyvC8n+xMRKVS5KPR24HF3P+buncBaoDEH+x2TGxuSpB2e2q6jdBEpbrko9B8DzWaWMLMK4Fpgaw72OyaNdTVMLUuwVsMuIlLkEqNtYGZrgJuApJm1A3cDJQDu/l1332pmjwObgDRwv7uPeIpjrpXEY1y3sFbno4tI0Ru10N199Ri2+QrwlZwkugjNDUn+des+XjtwjEtrK0PFEBEJqmC/KTrcqWkAdJQuIsUrEoW+IFnJvJpyDbuISFGLRKGbGasWJ3myrZOBtKbTFZHiFIlCB2hekqTrZD+b2jUNgIgUp8gU+spFScw0ji4ixSsyhT69spQr5lZrHF1EilZkCh0y0+k+t+sQR3v6Q0cREZl0kSr05oYk/Wnn6bYDoaOIiEy6SBX6my+dTnlJnHWtGnYRkeITqUIvS8S5ZsEMzY8uIkUpUoUOmWGXto5jvH74ROgoIiKTKoKFnplnXWe7iEixiVyhL5k1lZlVZTyhcXQRKTKRK/TBaQDWt3aS1jQAIlJEIlfokJkG4OCxXrbs7QodRURk0kSy0Fcu1nS6IlJ8IlnoM6umsGx2FetadfqiiBSPSBY6wKrFSX6z8xAnegdCRxERmRSRLfTmJSl6+9M8u/Ng6CgiIpMisoV+Tf0MSuMx1ulboyJSJCJb6OWlcZrqp+uDUREpGpEtdMhMp/vyG93s7z4ZOoqIyISLdKHfmJ0GYL2+NSoiRSDShb58zjRmVJZq2EVEikKkCz0WM25YVMu6Vztx1zQAIhJtkS50yAy77O/u4dX9R0NHERGZUJEv9FUNmWkA1m7T6YsiEm2RL/S5NeUsTFXqsnQiEnmRL3SA5sVJntl+kJ5+TQMgItFVHIXekOJE3wAbXjsUOoqIyIQpikK/blEtiZjpsnQiEmmjFrqZPWBm+83spVG2e4uZDZjZB3MXLzemliVYcUmNxtFFJNLGcoT+IHDz+TYwszjwZeAXOcg0IVYtTvHiniMcOtYbOoqIyIQYtdDdfS0w2hy0dwGPAPtzEWoiNC9J4g7r23SULiLRNO4xdDObB7wf+O4Ytr3dzFrMrKWjY3LPC79yXjVVUxIaRxeRyMrFh6L3AJ9z91HPCXT3+9y9yd2bUqlUDp567BLxGDcsquUJTQMgIhGVi0JvAh42s53AB4Fvm9l/zMF+c665IcWewyfY0XksdBQRkZxLjHcH7r5g8LaZPQg85u7/ON79ToTm7DQA61o7WZiaGjiNiEhujeW0xTXAU8BSM2s3s9vM7A4zu2Pi4+XWpbWV1M0o13S6IhJJox6hu/vqse7M3f9wXGkmwarFKR574XX6BtKUxIvie1UiUiSKrtFubEjS3dPPC7sPh44iIpJTRVfoNyxKEjM07CIikVN0hV5dUcKb5msaABGJnqIrdMhMp/v87sN0newLHUVEJGeKs9AbkgyknafaDoSOIiKSM0VZ6CsumU5FaVzTAIhIpBRloZcmYly3sFbj6CISKUVZ6JAZdtnReYzdB4+HjiIikhNFXeiAjtJFJDKKttAXpaYye9oUjaOLSGQUbaGbGasakqxv62Qgrel0RaTwFW2hQ2bY5fDxPl7acyR0FBGRcSvqQl+5WOPoIhIdRV3oyallLJ8zjSdendzL4YmITISiLnTIDLtseO0Qx3r6Q0cRERkXFXpDir4B59kdB0NHEREZl6Iv9Kb66ZQlYppOV0QKXtEX+pSSONcsmMG6Vo2ji0hhK/pCh8w4+rZ9R3njyMnQUURELpoKncx1RkGnL4pIYVOhA8tmV5GcWso6nb4oIgVMhQ7EYsbKxUnWtR4grWkARKRAqdCzmhtSdB7t4eU3ukNHERG5KCr0rFVD0wBo2EVECpMKPWt29RQaZk7V+egiUrBU6MOsakjy7I6DnOwbCB1FROSCqdCHubEhRU9/mpadh0JHERG5YCr0Ya5dOIOSuPGExtFFpACp0IepKE1w9SXTdVk6ESlIKvQz3LgkxebXu+g82hM6iojIBRm10M3sATPbb2YvjbD+981sU/bnSTNrzH3MyTN4+uJ6TQMgIgVmLEfoDwI3n2f9DuCt7n4l8BfAfTnIFcwV86qpLi/RsIuIFJxRC93d1wIjXv3B3Z9098HTQp4G5ucoWxDxmLFycS3rWjtx1zQAIlI4cj2Gfhvw8xzvc9I1N6TYe+QkbR1HQ0cRERmznBW6mb2NTKF/7jzb3G5mLWbW0tGRv6cGDo6j61ujIlJIclLoZnYlcD9wi7sfGGk7d7/P3ZvcvSmVSuXiqSdE3YwK6msrNI4uIgVl3IVuZpcAjwIfdfdt44+UH1Y1JHlq+wF6+9Oho4iIjMlYTltcAzwFLDWzdjO7zczuMLM7spv8OVALfNvMnjezlgnMO2maG1Ic7x1g4y5NAyAihSEx2gbuvnqU9R8HPp6zRHni+kW1xGPGutZOrl1YGzqOiMio9E3REUybUkLj/Gp9MCoiBUOFfh7NDSk2tR/myPG+0FFEREalQj+P5oYkaYcn23SULiL5T4V+Ho11NUwtS/CE5nURkQKgQj+PkniM6xbW8sSr+fslKBGRQSr0Udy4JMnugyd47cCx0FFERM5LhT4KTQMgIoVChT6KBclK5tWUaxoAEcl7KvRRmBmrFidZ39ZJ/4CmARCR/KVCH4PmJUm6T/azac+R0FFEREakQh+DlYuSmKFhFxHJayr0MZheWcoVc6tV6CKS11ToY9TckOS5XYc42tMfOoqIyDmp0MdoVUOS/rTzdNuI1+8QEQlKhT5Gb750OuUlcdZpGgARyVMq9DEqS8S5ZsEM1moaABHJUyr0C9DckGR7xzFeP3widBQRkbOo0C9Ac0PmwtY620VE8pEK/QIsmTWVmVVlmk5XRPKSCv0CDE0D0NpJOu2h44iInEaFfoGalyQ5eKyXLXu7QkcRETmNCv0CrdR0uiKSp1ToF2hm1RSWza7SVYxEJO+o0C9Cc0OSlp2HONE7EDqKiMgQFfpFWNWQoncgzbM7D4aOIiIyRIV+Ea6pn0FpPMY6DbuISB5RoV+E8tI4TfXTWbutE3edvigi+UGFfpHeecVsXtnXzQ83tIeOIiICqNAv2keuvZQbFtVy948307q/O3QcEREV+sWKx4y/+fBVVJTGufP7GznZpzNeRCQsFfo4zJo2ha/+XiMvv9HNF3+6JXQcESlyoxa6mT1gZvvN7KUR1puZ/a2ZtZrZJjO7Ovcx89fbls7k9hsX8tDTu/j5i3tDxxGRIjaWI/QHgZvPs/6dQEP253bgO+OPVVj+2+8spbGuhj9+ZBO7Dx4PHUdEitSohe7ua4HzfYPmFuD/esbTQI2ZzclVwEJQmohx760rwOGTD2+kbyAdOpKIFKFcjKHPA3YPu9+eXXYWM7vdzFrMrKWjI1pfyrmktoIv/e6b2LjrMF//l22h44hIEcpFods5lp3z2zbufp+7N7l7UyqVysFT55f3Ns5l9TV1fOfXbazdFq03LBHJf7ko9Hagbtj9+cDrOdhvQfrz91zOkllT+cwPnmd/98nQcUSkiOSi0H8C/EH2bJfrgCPuXrSne5SXxvnmR67maE8/n/mHF3RlIxGZNGM5bXEN8BSw1Mzazew2M7vDzO7IbvIzYDvQCvwf4L9MWNoCsWRWFXe/93LWtXby3bVtoeOISJFIjLaBu68eZb0Dn8hZooi49S11rG/t5Gv/vI1rF9Ty5kunh44kIhGnb4pOEDPjS7/7JubWTOGTazZy5Hhf6EgiEnEq9Ak0bUoJ966+mn1dJ/ncI5s01a6ITCgV+gS7qq6Gz928jMc3v8FDz+wKHUdEIkyFPgluW7WAm5am+IvHtrDl9a7QcUQkolTokyAWM776oUZqyku4c81zHO/tDx1JRCJIhT5JklPLuOfDV7Gj8xh3/3hz6DgiEkEq9El0w+Ikd71tMT/c0M4/btwTOo6IRIwKfZJ98u0NvKV+Ov/j/73Ijs5joeOISISo0CdZIh7jG7euoCQR4641z9HTr0vXiUhuqNADmFtTzlc+2MhLe7r4q5+/HDqOiESECj2Q314+iz+8oZ7vrd/Jv2zZFzqOiESACj2gP3nXMi6fO43//qMX2HvkROg4IlLgVOgBlSUyU+329af51Jrn6del60RkHFTogS1IVvLF91/BszsP8re/bA0dR0QKmAo9D7x/xXw+cPV87v3lqzzZ1hk6jogUKBV6nvjCLZezIFnJpx9+ngNHe0LHEZECpELPE5VlCe5dvYLDJ/r47A916ToRuXAq9Dxy+dxq/ue7L+PXr3TwwPodoeOISIFRoeeZj153Ke+4fBZffvxlXth9OHQcESkgKvQ8Y2b89QcamVk1hbvWbKTrpC5dJyJjo0LPQ9UVJXzj1qvYc/gEf/roi7p0nYiMiQo9TzXVz+Azv72Exzbt5Qctu0PHEZECoELPY3/01kWsWpzk7p9sZtu+7tBxRCTPqdDzWCxmfP3DjUwtS3Dn95/jZJ+m2hWRkanQ89zMqil87feuYtu+o3zhsS2h44hIHlOhF4C3Lklxx1sX8f1ndvHTTXtDxxGRPKVCLxCf/Z0lXFVXw+cf2cTug8dDxxGRPKRCLxAl8Rj3rl4BBneu2UifptoVkTOo0AtI3YwKvvyBK3lh92G++otXQscRkTyjQi8w73rTHH7/2kv432u38+tX9oeOIyJ5ZEyFbmY3m9krZtZqZp8/x/pqM/snM3vBzDab2cdyH1UG/dl7lrN0VhWf/cEL7O86GTqOiOSJUQvdzOLAt4B3AsuB1Wa2/IzNPgFscfdG4Cbga2ZWmuOskjWlJM43P7KCY739fPofnmdAU+2KCGM7Qr8GaHX37e7eCzwM3HLGNg5UmZkBU4GDQH9Ok8ppGmZV8YX3XcGTbQf40s+26ktHIjKmQp8HDJ9MpD27bLhvApcBrwMvAp9yd52GMcE+1DSfDzfV8XfrdnDjX/+K763foWIXKWJjKXQ7x7Izf8d/B/A8MBe4CvimmU07a0dmt5tZi5m1dHR0XHBYOZ2Z8eUPXsma/3wdC1OV/K9/2qJiFyliYyn0dqBu2P35ZI7Eh/sY8KhntAI7gGVn7sjd73P3JndvSqVSF5tZznD9oloevv16FbtIkRtLof8GaDCzBdkPOm8FfnLGNruAtwOY2SxgKbA9l0FldCp2keJmY7l4gpm9C7gHiAMPuPtfmtkdAO7+XTObCzwIzCEzRPNX7v7Q+fbZ1NTkLS0t44wv5/NU2wG+8W/beHr7QWZWlfFHNy1i9TWXMKUkHjqaiFwkM9vg7k3nXBfqajgq9MmjYheJDhW6ACp2kShQoctpVOwihUuFLuekYhcpPCp0Oa+n2g5wz79u45kdKnaRfKdClzFRsYvkPxW6XBAVu0j+UqHLRVGxi+QfFbqMi4pdJH+o0CUnVOwi4anQJadU7CLhqNBlQpxZ7O9tnMtlc6Zx2ZwqGmZWUZrQJWtFcu18hZ6Y7DASHdcvquX6RdfzVNsBvvWrVh56+jV6+jPXNSmJG4tSU1k+Z1q25DNFXzu1LHBqkehSocu4ZYq9lv6BNDsPHGPL3m627u1i694u1rd18ujGPUPbzqwq47I501g+N1Pyy+dUUV9bSSKuo3mR8VKhS84k4jEWz6xi8cwq3tc4d2j5gaM9bB1W8lv2drG+tZP+7MWtyxIxls6u4rLZmaP4y+ZMY9mcaVSXl4T6q4gUJI2hSxC9/Wla9x89reS37u3i0PG+oW3m1ZQPHc0vzxZ93fQKYrFzXRVRpDhoDF3yTmkilinquacuPevu7OvqOa3gt+7t4pcv7yN7ME9laZxlc04dyV82ZxrLZldRUap/yiI6Qpe8d6J3gG37uk8r+pf3dtPd0w+AGdTXVrI8W+6zqqdQXV5CdXkJNRUlQ7fLS+KY6eheCpuO0KWglZfGaayrobGuZmiZu9N+6MRpR/Iv7jnCT1/cO+J+SuMxppWXUF2eoKaidKjoz/wZ/iZQnb1dltA59pL/VOhSkMyMuhkV1M2o4B2Xzx5afry3nwNHezlyoo+uE30cPtHHkezP4eODtzPr93efZNu+bo6c6KP7ZP95n29KSYya8tKzir66vISaM+5Xl5cwrbyEskSM0kSM0njmz5J4jETM9FuCTBgVukRKRWmCihkJ6i7wcQNpp2t4+Q+7feR471lvCrsPHuel7LLjvQNjfh4zKIlnSr4kbkNFP7z0hy8vG1oWG7atDdv27DeNwceXxmMk4jHiscwbYNyMmBmxGJk/zYbWxbLrzcguN2IGsVj2MdnlsezyzLbZ29k3qaHH2NmPkcmhQhchU0rTK0uZXll6wY/t7U+fKv8Tg78d9NPbn6ZnIE1ff5q+gTS9g38O+NDtweW9A8O3yazv7uvn4LDH9Q04PWc8bvDUz3xnBkbmzcOG7mcXwmnLhm87uI7hjz/1sNP2B2euO/f+zsx1ztvYCMuHb2/nXH7mgnM95ta31PHx5oVn5RkvFbrIOJUmYqSqykhVTf63YNNppy996o3gzDeIvn4n7c6AO+7OQBrSnlmWHn77rPuZ31rS7viZt4e2z2yXdmcgnVl36rky2Qay+/LsMmfwTxg8H8PJLMgsO7We7DaDj2Fw/TnWndqfn1o3wvMNOrUnGOEmw08aOX35ubc/32OG30lO0DemVegiBSwWM8picX1oKwDo+9YiIhGhQhcRiQgVuohIRKjQRUQiQoUuIhIRKnQRkYhQoYuIRIQKXUQkIoJNn2tmHcBrF/nwJNCZwziFTq/H6fR6nKLX4nRReD0udffUuVYEK/TxMLOWkeYDLkZ6PU6n1+MUvRani/rroSEXEZGIUKGLiEREoRb6faED5Bm9HqfT63GKXovTRfr1KMgxdBEROVuhHqGLiMgZVOgiIhFRcIVuZjeb2Stm1mpmnw+dJyQzqzOzX5nZVjPbbGafCp0pNDOLm9lGM3ssdJbQzKzGzH5kZi9n/41cHzpTKGb2X7P/R14yszVmNiV0polQUIVuZnHgW8A7geXAajNbHjZVUP3AZ939MuA64BNF/noAfArYGjpEnvgG8Li7LwMaKdLXxczmAZ8Emtz9CiAO3Bo21cQoqEIHrgFa3X27u/cCDwO3BM4UjLvvdffnsre7yfyHnRc2VThmNh94N3B/6Cyhmdk04Ebg7wDcvdfdD4dNFVQCKDezBFABvB44z4QotEKfB+wedr+dIi6w4cysHlgBPBM2SVD3AH8MpEMHyQMLgQ7ge9khqPvNrDJ0qBDcfQ/wVWAXsBc44u7/HDbVxCi0QrdzLCv68y7NbCrwCPBpd+8KnScEM3sPsN/dN4TOkicSwNXAd9x9BXAMKMrPnMxsOpnf5BcAc4FKM/tPYVNNjEIr9Hagbtj9+UT0V6exMrMSMmX+9+7+aOg8Aa0E3mdmO8kMxf2WmT0UNlJQ7UC7uw/+xvYjMgVfjP4DsMPdO9y9D3gUuCFwpglRaIX+G6DBzBaYWSmZDzZ+EjhTMGZmZMZIt7r710PnCcnd/8Td57t7PZl/F79090gehY2Fu78B7DazpdlFbwe2BIwU0i7gOjOryP6feTsR/YA4ETrAhXD3fjO7E/gFmU+qH3D3zYFjhbQS+Cjwopk9n132p+7+s4CZJH/cBfx99uBnO/CxwHmCcPdnzOxHwHNkzgzbSESnANBX/0VEIqLQhlxERGQEKnQRkYhQoYuIRIQKXUQkIlToIiIRoUIXEYkIFbqISET8fwSo8olkX+rkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x=np.arange(0,10,1)\n",
    "V = 2/3\n",
    "y = V+np.exp(-x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
